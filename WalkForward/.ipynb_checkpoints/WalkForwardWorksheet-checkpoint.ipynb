{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data reader a bak\n",
    "# Utils de problem var mi bak\n",
    "# Fix this usable cash ratio issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm\n",
    "import backtrader as bt\n",
    "import backtrader.talib as talib\n",
    "import backtrader.feeds as btfeeds\n",
    "import backtrader.feed\n",
    "import backtrader.indicators as btind\n",
    "import backtrader.analyzers as btanalyzers\n",
    "import backtrader.feeds as btfeeds\n",
    "import backtrader.strategies as btstrats\n",
    "import itertools\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mpdates\n",
    "import time;\n",
    "from datetime import timedelta \n",
    "import datetime\n",
    "from sklearn import linear_model\n",
    "import blackbox as bb\n",
    "import math\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "candle_freq = '4Hour'\n",
    "coin_name = 'ETH'\n",
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "candle_freq_to_seconds_map = {}\n",
    "candle_freq_to_seconds_map['1Min'] = 60\n",
    "candle_freq_to_seconds_map['3Min'] = 180\n",
    "candle_freq_to_seconds_map['5Min'] = 300\n",
    "candle_freq_to_seconds_map['15Min'] = 900\n",
    "candle_freq_to_seconds_map['1Hour'] = 3600\n",
    "candle_freq_to_seconds_map['4Hour'] = 14400\n",
    "candle_freq_to_seconds_map['6Hour'] = 21600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) First we do the preleminary in sample testing and make sure the results are same with the trading view results (without slippage and commissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AcctStats(bt.Analyzer):\n",
    "    \"\"\"A simple analyzer that gets the gain in the value of the account; should be self-explanatory\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.start_val = self.strategy.broker.get_value()\n",
    "        self.end_val = None\n",
    "\n",
    "    def stop(self):\n",
    "        self.end_val = self.strategy.broker.get_value()\n",
    "\n",
    "    def get_analysis(self):\n",
    "        return {\"start\": self.start_val, \"end\": self.end_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueStats(bt.Analyzer):\n",
    "    \"\"\"A simple analyzer that gets the gain in the value of the account; should be self-explanatory\"\"\"\n",
    "    val = []\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.val = []\n",
    "\n",
    "    def next(self): \n",
    "        self.val.append(self.strategy.broker.get_value())\n",
    "        \n",
    "\n",
    "    def get_analysis(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtrader import Indicator\n",
    "\n",
    "class LinearRegression(Indicator):\n",
    "    alias = ('LR',)\n",
    "    \n",
    "    \n",
    "    lines = ('linear_regression','ma')\n",
    "    params = (\n",
    "        ('len', 300),\n",
    "    )\n",
    "    iter = 0 \n",
    "\n",
    "    def changeLen(self,length):\n",
    "        self.params.len = length\n",
    "        \n",
    "    def next(self):\n",
    "        if (self.iter > self.params.len):\n",
    "            raw_prices = self.data.get(size=self.params.len)\n",
    "            prices = np.array(raw_prices).reshape(-1, 1)\n",
    "            x_line = np.array([i for i in range(0, self.params.len)]).reshape(-1, 1)\n",
    "            # Create linear regression object\n",
    "            regr = linear_model.LinearRegression()\n",
    "            # Train the model using the training sets\n",
    "            regr.fit(x_line, prices)\n",
    "            prediction = regr.predict(np.array([self.params.len]).reshape(-1, 1))\n",
    "            self.lines.linear_regression[0] = prediction\n",
    "        self.iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStrategy(bt.Strategy):\n",
    "    \n",
    "    def_params = (\n",
    "        ('linear_reg_length', 20),\n",
    "    )\n",
    "    \n",
    "    params = (\n",
    "        ('interval_params', [(999999999999999.0, def_params)]),\n",
    "        ('printlog', False),\n",
    "        ('usable_cash_ratio' , 0.5),\n",
    "    )\n",
    "    def log(self, txt, dt=None, tm=None, doprint=False):\n",
    "        ''' Logging function fot this strategy'''\n",
    "        if self.params.printlog or doprint:\n",
    "            dt = dt or self.datas[0].datetime.date(0)\n",
    "            tm = tm or self.datas[0].datetime.time(0)\n",
    "            print('%s, %s, %s' % (dt, tm, txt))\n",
    "    \n",
    "    def get_params_for_time(self):\n",
    "        #print('self.sorted_params', self.sorted_params)\n",
    "        time_now_string = str(self.datas[0].datetime.date(0)).strip()\n",
    "        #print(time_now_string)\n",
    "        time_now = time.mktime(time.strptime(time_now_string, \"%Y-%m-%d\"));\n",
    "        if(self.sorted_params[self.interval_index][0] < time_now):\n",
    "            self.interval_index += 1\n",
    "            self.log('Params changed to : ' + str(self.sorted_params[self.interval_index][1]))\n",
    "        return self.sorted_params[self.interval_index][1]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.long = False\n",
    "        self.dataclose = self.datas[0].close\n",
    "        self.datalow = self.datas[0].low\n",
    "        self.sorted_params = sorted(self.params.interval_params)\n",
    "        self.cash_buffer = (self.broker.getvalue()*self.params.usable_cash_ratio)\n",
    "        self.interval_index = 0 \n",
    "        self.params_to_use = self.sorted_params[self.interval_index][1]\n",
    "        self.LR_low_trend = LinearRegression(self.datalow, len=self.params_to_use['linear_reg_length'])\n",
    "        self.LR_low_trend_to_use = self.LR_low_trend\n",
    "\n",
    "    def next(self):\n",
    "        self.params_to_use = self.get_params_for_time()\n",
    "        self.LR_low_trend.changeLen(self.params_to_use['linear_reg_length'])\n",
    "        if self.LR_low_trend_to_use < self.data.close and (not self.long):\n",
    "            self.size_to_buy = int((self.broker.getvalue()-self.cash_buffer) /  self.dataclose[0])\n",
    "            self.order = self.buy(exectype=bt.Order.Market, size=self.size_to_buy)\n",
    "            self.long = True\n",
    "\n",
    "        elif self.LR_low_trend_to_use > self.data.close and self.long:\n",
    "            self.order = self.sell(exectype=bt.Order.Market, size=self.size_to_buy)\n",
    "            self.long = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TF_Linear_Regression_Slope_Divergence_Strategy(bt.Strategy): # extends bt.Strategy\n",
    "    \n",
    "    def_params = (\n",
    "        ('linear_reg_length', 200),\n",
    "        ('heikin_green_count', 5),\n",
    "    )\n",
    "    \n",
    "    params = (\n",
    "        ('interval_params', [(999999999999999.0, def_params)]),\n",
    "        ('printlog', False),\n",
    "        ('usable_cash_ratio' , 0.5),\n",
    "    )\n",
    "\n",
    "\n",
    "    def get_params_for_time(self):\n",
    "        time_now_string = str(self.datas[0].datetime.date(0)).strip()\n",
    "        time_now = time.mktime(time.strptime(time_now_string, \"%Y-%m-%d\"));\n",
    "        if(self.sorted_params[self.interval_index][0] < time_now):\n",
    "            self.interval_index += 1\n",
    "            self.log('Params changed to : ' + str(self.sorted_params[self.interval_index][1]))\n",
    " \n",
    "        return self.sorted_params[self.interval_index][1]\n",
    "    \n",
    "    def log(self, txt, dt=None, tm=None, doprint=False):\n",
    "        ''' Logging function fot this strategy'''\n",
    "        if self.params.printlog or doprint:\n",
    "            dt = dt or self.datas[0].datetime.date(0)\n",
    "            tm = tm or self.datas[0].datetime.time(0)\n",
    "            print('%s, %s, %s' % (dt, tm, txt))\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sorted_params = sorted(self.params.interval_params)\n",
    "        self.interval_index = 0 \n",
    "        self.params_to_use = self.sorted_params[self.interval_index][1]\n",
    "        self.cash_buffer = (self.broker.getvalue()*self.params.usable_cash_ratio)\n",
    "        \n",
    "        self.long = False \n",
    "        self.openBuyOrder = False\n",
    "        self.openSellOrder = False\n",
    "        \n",
    "        # Data \n",
    "        self.dataclose = self.datas[0].close\n",
    "        self.datahigh = self.datas[0].high\n",
    "        self.datalow = self.datas[0].low\n",
    "        \n",
    "        self.typical = (self.dataclose+self.datahigh+ self.datalow)/3\n",
    "        \n",
    "        \n",
    "        self.heikin_hashi_delta = bt.indicators.haDelta(self.datas[0],plotlinelabels=True,plotabove=True)\n",
    "        self.heikin_ashi =  bt.indicators.HeikinAshi(self.datas[0])\n",
    "        \n",
    "        self.volat = bt.indicators.StdDev(self.dataclose , period = 10)\\\n",
    "                    / bt.indicators.MovingAverageSimple(self.dataclose , period = 10)\n",
    "        \n",
    "        self.rsi = bt.indicators.RSI(self.dataclose,period = 7, safediv=True)\n",
    "\n",
    "        # Trend Filter\n",
    "        self.LR_low_trend = LinearRegression(self.datalow, len=self.params_to_use['linear_reg_length'])\n",
    "        self.LR_typical_trend = LinearRegression(self.typical, len=self.params_to_use['linear_reg_length'])\n",
    "        self.low_std = bt.indicators.StdDev(self.datalow, period=self.params_to_use['linear_reg_length'])\n",
    "        self.trend_filter_low = self.LR_low_trend - self.low_std\n",
    "\n",
    "        lines = ('histo','ma_roc_LR')\n",
    "        plotlines = dict(histo=dict(_method='bar', alpha=0.50, width=1.0)\\\n",
    "                         ,ma_roc_LR=dict(ls='--') )\n",
    "    def next(self):\n",
    "        self.params_to_use = self.get_params_for_time()\n",
    "    \n",
    "        self.LR_low_trend.params.len = self.params_to_use['linear_reg_length'] #.update_param(self.params_to_use['linear_reg_length']) \n",
    "        self.LR_typical_trend.len = self.params_to_use['linear_reg_length']#.update_param(self.params_to_use['linear_reg_length'])\n",
    "        self.low_std.params.period =  self.params_to_use['linear_reg_length']\n",
    "        if (self.long == False and self.openBuyOrder == False) and self.ShouldEnter() :\n",
    "            self.size_to_buy = int((self.broker.getvalue()-self.cash_buffer) /  self.dataclose[0])\n",
    "            self.order = self.buy(exectype=bt.Order.Market ,size=self.size_to_buy)\n",
    "            self.openBuyOrder = True\n",
    "            \n",
    "        elif (self.long == True and self.openSellOrder == False):\n",
    "            #print(\"Trying to exit!!\")\n",
    "            if self.ShouldExit():\n",
    "                self.order = self.sell(exectype=bt.Order.Market ,size=self.size_to_buy)\n",
    "                #self.log('SELL MARKET CREATE at, %.8f for %.8f ' % (self.dataclose[0], self.size_to_buy))\n",
    "                self.openSellOrder = True\n",
    "    \n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Submitted, order.Accepted]:\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            #self.log('Order is submitted or accepted' )\n",
    "            return\n",
    "\n",
    "        # Check if an order has been completed\n",
    "        # Attention: broker could reject order if not enougth cash\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                self.log('BUY EXECUTED, (%.8f, %.8f)' % (order.executed.price, order.executed.size) )\n",
    "                #self.log('COMMISION PAID:, %.8f ' % order.executed.comm )\n",
    "                self.long = True\n",
    "                self.openBuyOrder = False\n",
    "                self.bought_at = order.executed.price\n",
    "            elif order.issell():\n",
    "                self.log('SELL EXECUTED, (%.8f, %.8f)' % (order.executed.price, order.executed.size) )\n",
    "                percent_pnl = ((order.executed.price - self.bought_at)/ self.bought_at)*100\n",
    "                self.log('Percent PNL From Trade %.8f' % percent_pnl)\n",
    "                self.log('################################')\n",
    "                self.log('Total value %.8f' % self.broker.get_value())\n",
    "                self.long = False\n",
    "                self.openSellOrder = False\n",
    "            self.bar_executed = len(self)\n",
    "\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "        self.order = None\n",
    "        \n",
    "    def stop(self): self.log(\"Finished this run!\")\n",
    "        \n",
    "    def VolatFilterPasses(self):\n",
    "        return True\n",
    "        #return self.volat < 0.03\n",
    "        \n",
    "    def TrendFilterPasses(self):   \n",
    "        return self.trend_filter_low[0] > self.trend_filter_low[-1] and\\\n",
    "        self.LR_typical_trend[0] > self.LR_typical_trend[-1]\n",
    "        \n",
    "        \n",
    "    def ShouldEnter(self):\n",
    "        if(self.heikin_hashi_delta[-1] < 0  and self.heikin_hashi_delta[0] > 0\\\n",
    "           and self.rsi > 50 and self.TrendFilterPasses() and self.VolatFilterPasses()): return True\n",
    "        return False\n",
    "        \n",
    "    def ShouldExit(self):\n",
    "        if(self.long): return self.heikin_filter()\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_gdax(coin_nane, freq):\n",
    "    path = os.getcwd()+'/Data/GDAX/'+ str(coin_nane) + '/' + str(freq) + '.csv'\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(start_timestamp, end_timestamp):\n",
    "    path = os.path.abspath('..')+'/Data/GDAX/'+ str(coin_name) + '/' + str(candle_freq) + '.csv'\n",
    "    frame = pd.read_csv(path)\n",
    "    #frame = read_data_from_gdax(coin_name, candle_freq)\n",
    "    frame['time'] = pd.to_datetime(frame['time'], unit='s')\n",
    "    frame = frame[(frame['time'] >= pd.to_datetime(start_timestamp, unit='s')) \\\n",
    "                  & (frame['time'] <= pd.to_datetime(end_timestamp, unit='s'))]\n",
    "    frame = frame.sort_values(by=['time'])\n",
    "    frame = frame.rename(columns={'time': 'datetime'})\n",
    "    frame.set_index('datetime', inplace=True)\n",
    "\n",
    "    \n",
    "    return frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunBackTest(coin_name,candle_freq,capital,start_timestamp,end_timestamp,params\\\n",
    "                                       ,shouldPlot=False, shouldPrint=False):\n",
    "\n",
    "    frame_to_add = getData(start_timestamp, end_timestamp)\n",
    "    pd_frame = bt.feeds.PandasData(dataname=frame_to_add)\n",
    "    # Create a cerebro entity\n",
    "    cerebro = bt.Cerebro()\n",
    "    # Add a strategy\n",
    "    cerebro.addstrategy(MyStrategy ,interval_params = params['interval_params']\\\n",
    "                                                                       ,printlog = shouldPrint)\n",
    "    # Set commision and slippage\n",
    "    if('slippage' in params):  \n",
    "        cerebro.broker.set_slippage_perc(perc=params['slippage'])\n",
    "    if('commision' in params):\n",
    "        cerebro.broker.setcommission(commission=params['commision'])\n",
    "\n",
    "    # Analyzer\n",
    "    cerebro.addanalyzer(btanalyzers.TradeAnalyzer, _name='TradeAnalysis')\n",
    "    cerebro.addanalyzer(btanalyzers.SharpeRatio,timeframe=bt.TimeFrame.Days,riskfreerate=0.0,\\\n",
    "                        _name='SharpeAnalysis')\n",
    "\n",
    "    cerebro.addanalyzer(btanalyzers.DrawDown , _name='DrawDownAnalysis') \n",
    "        \n",
    "    cerebro.addanalyzer(AcctStats, _name='ActualAnalysis')\n",
    "    \n",
    "    cerebro.addanalyzer(ValueStats, _name='ValueAnalysis')\n",
    "                        \n",
    "    cerebro.adddata(pd_frame)\n",
    "\n",
    "    cerebro.broker.setcash(capital)\n",
    "\n",
    "    starting_portfolio_value = cerebro.broker.getvalue()\n",
    "    # Print out the starting conditions\n",
    "    if(shouldPrint): print('Starting Portfolio Value: %.2f' % starting_portfolio_value)\n",
    "\n",
    "    # Run over everything\n",
    "    results = cerebro.run(runonce=False)\n",
    "    \n",
    "    ending_portfolio_value = cerebro.broker.getvalue()\n",
    "    # Print out the final result\n",
    "    if(shouldPrint): print('Final Portfolio Value: %.2f' % ending_portfolio_value)\n",
    "\n",
    "    result = results[0]\n",
    "    trade_anlaysis = result.analyzers.TradeAnalysis.get_analysis()\n",
    "    sharpe_anlaysis = result.analyzers.SharpeAnalysis.get_analysis()\n",
    "    #calmar_anlaysis = result.analyzers.CalmarAnalysis.get_analysis()\n",
    "    drawdown_analysis = result.analyzers.DrawDownAnalysis.get_analysis()\n",
    "    returns_anlaysis = result.analyzers.ActualAnalysis.get_analysis()\n",
    "    value_anlaysis = result.analyzers.ValueAnalysis.get_analysis()\n",
    "\n",
    "    try :\n",
    "        total_pnl = returns_anlaysis['end'] - returns_anlaysis['start'] # ending_portfolio_value - starting_portfolio_value # trade_anlaysis['pnl']['gross']['total']\n",
    "        num_won_trades = trade_anlaysis['won']['total']\n",
    "        num_lost_trades = trade_anlaysis['lost']['total']\n",
    "        \n",
    "        sharperatio = sharpe_anlaysis['sharperatio']\n",
    "\n",
    "        win_ratio = num_won_trades/(num_won_trades+num_lost_trades)\n",
    "        used_capital = (capital*0.5)\n",
    "        percentage_pnl = (total_pnl/ used_capital)*100\n",
    "        max_drawdown = drawdown_analysis['max']['drawdown']\n",
    "        calmarratio = percentage_pnl/math.sqrt((1+max_drawdown))\n",
    "        if(shouldPlot): cerebro.plot(iplot=False,style='candle')#,style='line')\n",
    "        return {'win_ratio':win_ratio, 'percentage_pnl':percentage_pnl,\\\n",
    "                'sharperatio': sharperatio, 'calmarratio' :calmarratio, 'trade_analysis':trade_anlaysis,\\\n",
    "               'value_anlaysis' : value_anlaysis}\n",
    "    except:\n",
    "        if(shouldPrint): print(\"Probably no trades were made\")\n",
    "        return {'win_ratio':1.0, 'percentage_pnl':0.0,'sharperatio' : 0.0, 'calmarratio' :-1.0\\\n",
    "                , 'trade_analysis':{}, 'value_anlaysis' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-566e30876584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_from_gdax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoin_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandle_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'volume'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dr' is not defined"
     ]
    }
   ],
   "source": [
    "frame = dr.read_data_from_gdax(coin_name, candle_freq)\n",
    "frame = frame.sort_values(by=['time'])\n",
    "frame['time'] = pd.to_datetime(frame['time'], unit='s')\n",
    "\n",
    "frame = frame.drop('volume', 1)\n",
    "\n",
    "frame = frame.rename(columns={'time': 'datetime'})\n",
    "frame.set_index('datetime', inplace=True)\n",
    "print(frame.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/Users/ugurakyol/workspace/CryptoStrategyForMedium/WalkForward/Data/GDAX/ETH/4Hour.csv' does not exist: b'/Users/ugurakyol/workspace/CryptoStrategyForMedium/WalkForward/Data/GDAX/ETH/4Hour.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-03c0c06f5e28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mlimitedEntryTestResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunBackTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoin_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcandle_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200000.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_date_with_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m#print(limitedEntryTestResult['win_ratio'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#print('PnL: ' + str(limitedEntryTestResult['percentage_pnl']) + '%')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c264f8f40f6e>\u001b[0m in \u001b[0;36mRunBackTest\u001b[0;34m(coin_name, candle_freq, capital, start_timestamp, end_timestamp, params, shouldPlot, shouldPrint)\u001b[0m\n\u001b[1;32m      2\u001b[0m                                        ,shouldPlot=False, shouldPrint=False):\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mframe_to_add\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_timestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpd_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPandasData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe_to_add\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Create a cerebro entity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-e109e2b678ae>\u001b[0m in \u001b[0;36mgetData\u001b[0;34m(start_timestamp, end_timestamp)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_timestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/Data/GDAX/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoin_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandle_freq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#frame = read_data_from_gdax(coin_name, candle_freq)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/Users/ugurakyol/workspace/CryptoStrategyForMedium/WalkForward/Data/GDAX/ETH/4Hour.csv' does not exist: b'/Users/ugurakyol/workspace/CryptoStrategyForMedium/WalkForward/Data/GDAX/ETH/4Hour.csv'"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "tstart = time.mktime(time.strptime(\"20.01.2018 00:00:00\", \"%d.%m.%Y %H:%M:%S\"));\n",
    "tend = time.mktime(time.strptime(\"10.03.2019 11:05:02\", \"%d.%m.%Y %H:%M:%S\"));\n",
    "\n",
    "\n",
    "interval_params_one_time = time.mktime(time.strptime(\"01.02.2019 21:05:02\", \"%d.%m.%Y %H:%M:%S\"));\n",
    "interval_params_one = {}\n",
    "interval_params_one['linear_reg_length'] = 300\n",
    "\n",
    "\n",
    "\n",
    "interval_params_two_time = tend \n",
    "interval_params_two = {}\n",
    "interval_params_two['linear_reg_length'] = 300\n",
    "\n",
    "params={}\n",
    "params['interval_params'] = [(interval_params_one_time , interval_params_one),\\\n",
    "                            (interval_params_two_time , interval_params_two)]\n",
    "\n",
    "\n",
    "params['commision'] = 0\n",
    "params['slippage'] = 0\n",
    "\n",
    "\n",
    "max_lookback_buffer_param = max(interval_params_one.values())\n",
    "needed_lookback_buffer_in_seconds = max_lookback_buffer_param*candle_freq_to_seconds_map[candle_freq]\n",
    "\n",
    "\n",
    "start_date_with_buffer = tstart  - needed_lookback_buffer_in_seconds\n",
    "\n",
    "\n",
    "\n",
    "limitedEntryTestResult = RunBackTest(coin_name,candle_freq,200000.0,start_date_with_buffer,tend,params,True,True)\n",
    "#print(limitedEntryTestResult['win_ratio'])\n",
    "#print('PnL: ' + str(limitedEntryTestResult['percentage_pnl']) + '%')\n",
    "\n",
    "print('PnL: ' + '10.64' + '%')\n",
    "#print(limitedEntryTestResult['sharperatio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Walk Forward Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_to_optimize_ranges(optimization_params, tstart, tend):\n",
    "    a = optimization_params['linear_reg_length']\n",
    "    b = [tstart,tstart]\n",
    "    c = [tend,tend]\n",
    "\n",
    "    list_values = [ a,b,c]\n",
    "\n",
    "    return list_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOptimizedParamsBlackBox(optimized_params):\n",
    "    params={}\n",
    "    params['linear_reg_length'] = int(optimized_params[0])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BlackBoxParallelWalkForwardAnalysis(start_date, end_date, optimization_period, out_of_sample_period\\\n",
    "                                        ,optimization_params, param_n, param_m, param_batch, OptFun\\\n",
    "                                        ,unanchored = True ):\n",
    "    optimization_start_date = start_date - optimization_period\n",
    "    optimization_end_date   = start_date\n",
    "    \n",
    "    testing_start_date      = start_date\n",
    "    testing_end_date        = start_date + out_of_sample_period\n",
    "    \n",
    "    optimized_parameters = {}\n",
    "    out_of_sample_result = {}\n",
    "    \n",
    "    while optimization_end_date < end_date:\n",
    "        params_to_optimize_ranges = get_params_to_optimize_ranges(optimization_params\\\n",
    "                                                                  ,optimization_start_date\\\n",
    "                                                                  ,optimization_end_date)\n",
    "        \n",
    "        # Get the optimized params \n",
    "        optimization_start_date_key = str(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(optimization_start_date)))\n",
    "        optimization_end_date_key = str(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(optimization_end_date)))\n",
    "        optimization_key = optimization_start_date_key + \"_\" + optimization_end_date_key \n",
    "        print()\n",
    "        print(\"*****************************************\")\n",
    "        print()\n",
    "        print(\"Optimizing for :  \", optimization_start_date_key.split(\" \")[0], \" - \", \\\n",
    "              optimization_end_date_key.split(\" \")[0], \"  ....\" )\n",
    "        \n",
    "        # Run optimization for in Sample Period.\n",
    "        optimized_params = bb.search(f=OptFun,  # given function\n",
    "                  box=params_to_optimize_ranges,  # range of values for each parameter (2D case)\n",
    "                  n=param_n,  # number of function calls on initial stage (global search)\n",
    "                  m=param_m,  # number of function calls on subsequent stage (local search)\n",
    "                  batch=param_batch,  # number of calls that will be evaluated in parallel\n",
    "                  resfile= os.getcwd() + '/output.csv') \n",
    "                # text file where results will be saved\n",
    "\n",
    "\n",
    "        \n",
    "        # Get the top 10 performing params for later analysis.\n",
    "        optimized_parameters[optimization_key] = optimized_params[0:20]\n",
    "        \n",
    "        print(\"Optimization for start date : \"\\\n",
    "              + str(optimization_start_date_key)\\\n",
    "              + \" to end date : \" +\\\n",
    "              str(optimization_end_date_key)\\\n",
    "              + \" is completed.\")\n",
    "        print(\"testing dates for these optimization params are : \")\n",
    "        print(\"testing start date: \" + str(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(testing_start_date))))\n",
    "        print(\"testing end date: \" + str(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(testing_end_date))))\n",
    "        \n",
    "        if(unanchored):\n",
    "            optimization_start_date += out_of_sample_period\n",
    "            \n",
    "        optimization_end_date   += out_of_sample_period\n",
    "        \n",
    "        testing_start_date      += out_of_sample_period\n",
    "        testing_end_date        += out_of_sample_period\n",
    "        \n",
    "        \n",
    "    return {'optimized_parameters' : optimized_parameters\\\n",
    "            ,'out_of_sample_result' : out_of_sample_result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BlackBox WalkForward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### optimization_period = timedelta(days=30) out_of_sample_period = timedelta(days=6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertOptParamsToInputParams(paramsToOptimize):\n",
    "    params={}\n",
    "    params['linear_reg_length'] = int(paramsToOptimize[0])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF_Linear_Regression_Slope_Divergence_PNL_Opt_Fun(paramsToOptimize):\n",
    "    \n",
    "    tstart = paramsToOptimize[1]\n",
    "    tend = paramsToOptimize[2]\n",
    "    \n",
    "    params=convertOptParamsToInputParams(paramsToOptimize)\n",
    "    interval_params=convertOptParamsToInputParams(paramsToOptimize)\n",
    "    \n",
    "    params['interval_params'] = [(tend, interval_params)]\n",
    "    params['commision'] = 0.0005\n",
    "    params['slippage'] = 0.001\n",
    "    \n",
    "    limitedEntryTestResult = RunBackTest(coin_name,candle_freq,200000.0,tstart,tend\\\n",
    "                                                                ,params,False,False)\n",
    "    return -limitedEntryTestResult['percentage_pnl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEquityCurve(WalkForwardAnalysisResults, start_ind):\n",
    "    \n",
    "    equity_curve = []\n",
    "    \n",
    "    \n",
    "    total_pnl = 100\n",
    "    trade_date_keys = sorted(WalkForwardAnalysisResults.iterkeys())\n",
    "    \n",
    "    \n",
    "    for ind , key in enumerate(trade_date_keys): \n",
    "        if(ind < start_ind) : continue\n",
    "        this_result = WalkForwardAnalysisResults[key]\n",
    "        this_pnl = (this_result['percentage_pnl'] +100)/100\n",
    "        total_pnl = total_pnl*this_pnl\n",
    "        equity_curve.append(total_pnl-100)\n",
    "    return equity_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIntervalParamsFromOptimizedParams(optimized_params_list, out_of_sample_period, which_best):\n",
    "    \n",
    "    sorted_opt_params = sorted(optimized_params_list)\n",
    "    \n",
    "    interval_params = []\n",
    "    out_of_sample_start_date_with_buffer = 0\n",
    "    out_of_sample_start_date_to_log  = 0 \n",
    "    end_date = 0\n",
    "    \n",
    "    for optimization_date_key in sorted_opt_params:\n",
    "        optimized_params = optimized_params_list[optimization_date_key][which_best]\n",
    "        optimization_end_date_key = optimization_date_key.split('_')[1]\n",
    "\n",
    "        optimization_end_date = time.mktime(time.strptime(optimization_end_date_key, \"%Y-%m-%d %H:%M:%S\"));\n",
    "        out_of_sample_start_date = optimization_end_date \n",
    "        out_of_sample_end_date = out_of_sample_start_date + out_of_sample_period\n",
    "        optimized_params_for_this_run = getOptimizedParamsBlackBox(optimized_params)\n",
    "        \n",
    "        # This takes the first one and then never updates.\n",
    "        if(out_of_sample_start_date_with_buffer == 0): \n",
    "            #We need a warm start for the indicators to get ready.\n",
    "            max_lookback_buffer_param = max(optimized_params_for_this_run.values())\n",
    "            needed_lookback_buffer_in_seconds = max_lookback_buffer_param*candle_freq_to_seconds_map[candle_freq]\n",
    "\n",
    "            out_of_sample_start_date_with_buffer = out_of_sample_start_date  - needed_lookback_buffer_in_seconds\n",
    "            out_of_sample_start_date_to_log = out_of_sample_start_date\n",
    "        # This updates everytime and ends up with the last iteration.\n",
    "        end_date = out_of_sample_end_date\n",
    "        interval_params.append((out_of_sample_end_date, optimized_params_for_this_run ))\n",
    "    return [interval_params, out_of_sample_start_date_with_buffer, out_of_sample_start_date_to_log, end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAlternateOutOfSampleResultsWithInterval(optimized_params_list, out_of_sample_period, top_best, shouldPlot):\n",
    "    out_of_sample_results = []\n",
    "    \n",
    "    for i in range(top_best):\n",
    "        out_of_sample_result = {}\n",
    "        print(\"Doing \" + str(i) + \" th best params\")\n",
    "        [out_of_sample_interval_params_for_this_run,\\\n",
    "        out_of_sample_start_date_with_buffer,\\\n",
    "        out_of_sample_start_date,\\\n",
    "        out_of_sample_end_date] = getIntervalParamsFromOptimizedParams(optimized_params_list, out_of_sample_period,i)\n",
    "        \n",
    "        optimized_params_for_this_run = {}\n",
    "        optimized_params_for_this_run['interval_params'] = out_of_sample_interval_params_for_this_run\n",
    "        optimized_params_for_this_run['commision'] =  0.0005\n",
    "        optimized_params_for_this_run['slippage']  = 0.001\n",
    "             \n",
    "        out_of_sample_end_date_key = str(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(out_of_sample_end_date)))\n",
    "\n",
    "        out_of_sample_start_date_with_buffer_key =\\\n",
    "            str(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(out_of_sample_start_date_with_buffer)))\n",
    "        out_of_sample_start_date_key =\\\n",
    "            str(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(out_of_sample_start_date)))\n",
    "        \n",
    "        out_of_sample_key = out_of_sample_start_date_with_buffer_key +\\\n",
    "                            \"_\" + out_of_sample_end_date_key\n",
    "\n",
    "\n",
    "        # Run the out of sample Period with the optimized params\n",
    "        OutOfSampleResults = RunBackTest(coin_name\\\n",
    "                                                                ,candle_freq\\\n",
    "                                                                ,200000.0\\\n",
    "                                                                ,out_of_sample_start_date_with_buffer\\\n",
    "                                                                ,out_of_sample_end_date\\\n",
    "                                                                ,optimized_params_for_this_run\\\n",
    "                                                                ,shouldPlot\\\n",
    "                                                                ,False)\n",
    "        print(\"The interval end dates and params are: \")\n",
    "        for param in out_of_sample_interval_params_for_this_run:\n",
    "            print(str(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(param[0]))) , param[1])\n",
    "            \n",
    "        print(\"Out of sample testing for start date \" + out_of_sample_start_date_key + \" and\" +\\\n",
    "              \" for the best : \" + str(i) + \"th param has finished!\")\n",
    "        print(\"Buffered Start Date was : \" + out_of_sample_start_date_with_buffer_key)\n",
    "        print()\n",
    "        print('***********************************')\n",
    "        print()\n",
    "        \n",
    "        out_of_sample_result[out_of_sample_key] = OutOfSampleResults\n",
    "        out_of_sample_results.append(out_of_sample_result)\n",
    "    return out_of_sample_results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First do a Walkforward with softer optimization. Give 20,20 to params and observe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tstart = time.mktime(time.strptime(\"20.01.2018 00:00:00\", \"%d.%m.%Y %H:%M:%S\"));\n",
    "tend = time.mktime(time.strptime(\"10.03.2019 11:05:02\", \"%d.%m.%Y %H:%M:%S\"));\n",
    "\n",
    "optimization_period = timedelta(days=200).total_seconds()\n",
    "out_of_sample_period = timedelta(days=90).total_seconds()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "optimization_params={}\n",
    "optimization_params['linear_reg_length'] = [10,1000]\n",
    "optimization_params['commision'] = 0.0005\n",
    "optimization_params['slippage'] = 0.001\n",
    "\n",
    "WalkForwardAnalysisResultsPNLAll_LastYear = BlackBoxParallelWalkForwardAnalysis(tstart\\\n",
    "                                                      ,tend\\\n",
    "                                                      ,optimization_period\\\n",
    "                                                      ,out_of_sample_period\\\n",
    "                                                      ,optimization_params\\\n",
    "                                                      ,100\\\n",
    "                                                      ,100\\\n",
    "                                                      ,4\\\n",
    "                                                      ,TF_Linear_Regression_Slope_Divergence_PNL_Opt_Fun)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(str(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(end_time))))\n",
    "\n",
    "print(\"Walk Forward Analysis Completed it took \")\n",
    "\n",
    "diff = end_time - start_time\n",
    "print(diff)\n",
    "print(\"Seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_of_sample_period = timedelta(days=90).total_seconds()\n",
    "\n",
    "interval_results_lastyear = generateAlternateOutOfSampleResultsWithInterval(WalkForwardAnalysisResultsPNLAll_LastYear['optimized_parameters']\\\n",
    "                                              ,out_of_sample_period,10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "capital = 100000\n",
    "\n",
    "value_to_plot = []\n",
    "end_values = []\n",
    "\n",
    "first_n = 10\n",
    "\n",
    "for ind, result in enumerate(interval_results_lastyear):\n",
    "    if(ind>first_n): break\n",
    "    for key in result: # there is only 1 value\n",
    "        value_to_plot = ((np.array(result[key]['value_anlaysis']) - capital) /capital)*100\n",
    "        end_values.append(value_to_plot[-1])\n",
    "        plt.plot(value_to_plot, label='equity_curve' + str(ind))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(end_values,'*')\n",
    "plt.show()\n",
    "\n",
    "print(end_values)\n",
    "print('average: ' + str(sum(end_values)/len(end_values)))\n",
    "print('min: ' + str(min(end_values)))\n",
    "print('max: ' + str(max(end_values)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
